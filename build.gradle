apply plugin: 'java'
//apply plugin: 'antlr'
apply plugin: 'me.champeau.gradle.antlr4'
apply plugin: "eclipse"

buildscript {
    repositories {
        maven {
            name 'JFrog OSS snapshot repo'
            url  'https://oss.jfrog.org/oss-snapshot-local/'
        }
        jcenter()
    }

    dependencies {
        //https://github.com/melix/antlr4-gradle-plugin
        classpath 'me.champeau.gradle:antlr4-gradle-plugin:0.1'
    }
}

repositories {
	mavenCentral()
    jcenter()
}

antlr4{
	source=file("src/main/antlr")
	output=file("src/main/java/hivesql/analysis/parse")
	//extraArgs=['-Werror']
}

dependencies {
	compile "org.antlr:antlr4:4.5.3"
	
    compile 'ch.qos.logback:logback-classic:1.1.7'
    compile 'ch.qos.logback:logback-core:1.1.7'
    compile 'org.slf4j:slf4j-api:1.7.13'
    compile group: 'org.apache.commons', name: 'commons-collections4', version: '4.1'
    compile 'com.google.code.gson:gson:2.6.2'
    compile group: 'org.apache.commons', name: 'commons-lang3', version: '3.4'
    

    testCompile group: 'org.testng', name: 'testng', version: '6.9.10'
    
    compile project('common-ast')

}
configurations {
    //重要。实际使用中，如果没有下面两行配置，则roll-over时，active log会发生改变。
    compile.exclude module: 'log4j'
    compile.exclude module: 'slf4j-log4j12'
}

//compileJava.dependsOn antlr4


/**
How to run:
	gradle grunGui -PsqlFileName=b_test.sql
*/
if(project.properties.containsKey('sqlFileName')){
	task grunGui(dependsOn:compileJava, type: JavaExec) {
		classpath = sourceSets.main.runtimeClasspath
		main='org.antlr.v4.gui.TestRig'
		args 'hivesql.analysis.parse.HiveSQL', 'stat', '-gui', '-trace', '-diagnostics', '-tokens', "${project.projectDir}/src/test/resources/${sqlFileName}"
	}
}

task testAllSqls(){}

def generateSqlFilePrefix="auto_"

file("${project.projectDir}/src/test/resources/").eachFileMatch{
		fileName-> fileName.endsWith(".sql") && fileName.startsWith(generateSqlFilePrefix)
	} {
		File file->
			def taskName="task_test_${file.name}"
			task (taskName, dependsOn:compileJava, type: JavaExec) {
				classpath = sourceSets.main.runtimeClasspath
				main='org.antlr.v4.gui.TestRig'
				args 'hivesql.analysis.parse.HiveSQL', 'stat', '-diagnostics', "${file.absolutePath}"
			}
			testAllSqls.dependsOn taskName
	}



/**
* 
*/

def convertFileToLowerCase(String inputFile, String outputFile){
	println "file conversion:"
	def content = new File(inputFile).text.toCharArray()
	def targetFile = new File(outputFile)
	if(targetFile.exists()){
		targetFile.delete()
		println "\tremove:${outputFile}"
	}
	for(int i=0;i<content.length;i++){
		char c=content[i]
		if(c>='A' && c<='Z'){
			//'a'-'A'+c :结果类型是String。很奇怪
			def d= (char)( ((int)'a')-((int)'A') + (int)c )
			//println "convert ${c} to ${d}"
			targetFile << d
		}else{
			targetFile << c
		}
	}
	println "\tinputFile=${inputFile}"
	println "\toutputFile=${outputFile}"
	println ""
}

task testFileConvert()<<{
	convertFileToLowerCase("${project.projectDir}/src/test/resources/i_test.sql", "${project.projectDir}/src/test/resources/auto_i_test.sql")
}

task convertFiles()<<{
	file("${project.projectDir}/src/test/resources/").eachFileMatch{
		fileName-> fileName.endsWith(".sql") && !fileName.startsWith(generateSqlFilePrefix)
	} {
		File file->
			convertFileToLowerCase(file.getAbsolutePath(), file.getParentFile().getAbsolutePath()+"/${generateSqlFilePrefix}"+file.getName())
	}
}


